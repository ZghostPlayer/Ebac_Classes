{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBAC - Regressão II - regressão múltipla\n",
    "\n",
    "## Tarefa I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previsão de renda II\n",
    "\n",
    "Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que é a base do seu próximo projeto. Vamos usar os recursos que vimos até aqui nesta base.\n",
    "\n",
    "|variavel|descrição|\n",
    "|-|-|\n",
    "|data_ref                | Data de referência de coleta das variáveis |\n",
    "|index                   | Código de identificação do cliente|\n",
    "|sexo                    | Sexo do cliente|\n",
    "|posse_de_veiculo        | Indica se o cliente possui veículo|\n",
    "|posse_de_imovel         | Indica se o cliente possui imóvel|\n",
    "|qtd_filhos              | Quantidade de filhos do cliente|\n",
    "|tipo_renda              | Tipo de renda do cliente|\n",
    "|educacao                | Grau de instrução do cliente|\n",
    "|estado_civil            | Estado civil do cliente|\n",
    "|tipo_residencia         | Tipo de residência do cliente (própria, alugada etc)|\n",
    "|idade                   | Idade do cliente|\n",
    "|tempo_emprego           | Tempo no emprego atual|\n",
    "|qt_pessoas_residencia   | Quantidade de pessoas que moram na residência|\n",
    "|renda                   | Renda em reais|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('previsao_de_renda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             15000 non-null  int64  \n",
      " 1   data_ref               15000 non-null  object \n",
      " 2   id_cliente             15000 non-null  int64  \n",
      " 3   sexo                   15000 non-null  object \n",
      " 4   posse_de_veiculo       15000 non-null  bool   \n",
      " 5   posse_de_imovel        15000 non-null  bool   \n",
      " 6   qtd_filhos             15000 non-null  int64  \n",
      " 7   tipo_renda             15000 non-null  object \n",
      " 8   educacao               15000 non-null  object \n",
      " 9   estado_civil           15000 non-null  object \n",
      " 10  tipo_residencia        15000 non-null  object \n",
      " 11  idade                  15000 non-null  int64  \n",
      " 12  tempo_emprego          12427 non-null  float64\n",
      " 13  qt_pessoas_residencia  15000 non-null  float64\n",
      " 14  renda                  15000 non-null  float64\n",
      "dtypes: bool(2), float64(3), int64(4), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
    "2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?\n",
    "3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?\n",
    "4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?\n",
    "5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?\n",
    "6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n",
    "7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do conjunto de treino: 11250\n",
      "Tamanho do conjunto de teste: 3750\n"
     ]
    }
   ],
   "source": [
    "# Separar os dados em variáveis independentes (X) e variável dependente (y)\n",
    "X = df.drop('renda', axis=1)\n",
    "y = df['renda']\n",
    "\n",
    "# Dividir os dados em conjunto de treino e teste (75% treino, 25% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Verificar o tamanho dos conjuntos de treino e teste\n",
    "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]}\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor alpha: 0.1\n",
      "Melhor R^2 no conjunto de validação: 0.2551049519421988\n",
      "R^2 no conjunto de teste: 0.2672790656792706\n"
     ]
    }
   ],
   "source": [
    "# Separar os dados em variáveis independentes (X) e variável dependente (y)\n",
    "X = df.drop('renda', axis=1)\n",
    "y = df['renda']\n",
    "\n",
    "# Identificar colunas numéricas e categóricas\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Criar pré-processadores para numéricas e categóricas, incluindo tratamento de valores faltantes\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),  # Preencher valores faltantes com a média\n",
    "            ('scaler', StandardScaler())  # Escalar os dados\n",
    "        ]), numeric_features),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),  # Preencher valores faltantes com a moda\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Codificar variáveis categóricas\n",
    "        ]), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Criar um pipeline com pré-processamento e modelo Ridge\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "# Definir os parâmetros para GridSearch\n",
    "param_grid = {\n",
    "    'ridge__alpha': [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "# Configurar o GridSearchCV para encontrar o melhor alpha\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Dividir os dados em conjunto de treino e teste (75% treino, 25% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Ajustar o modelo aos dados de treino\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Exibir os melhores parâmetros e o melhor score\n",
    "print(\"Melhor alpha:\", grid_search.best_params_['ridge__alpha'])\n",
    "print(\"Melhor R^2 no conjunto de validação:\", grid_search.best_score_)\n",
    "print(\"R^2 no conjunto de teste:\", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Desempenho Comparativo:***\n",
    "O modelo atual com Ridge Regression tem um R² menor (0.267) em comparação ao modelo anterior do último exercício utilizado na base(0.353). Isso sugere que o modelo anterior estava explicando mais variabilidade da renda em relação ao modelo atual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor R^2 no conjunto de validação: 0.2572761851751699\n",
      "R^2 no conjunto de teste: 0.26795606083216295\n"
     ]
    }
   ],
   "source": [
    "# Criar o pipeline com o modelo LASSO\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lasso', Lasso())\n",
    "])\n",
    "\n",
    "# Definir os parâmetros para GridSearch\n",
    "param_grid = {\n",
    "    'lasso__alpha': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Configurar o GridSearchCV para encontrar o melhor alpha\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Ajustar o modelo aos dados de treino\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Exibir os melhores parâmetros e o melhor score\n",
    "print(\"Melhor R^2 no conjunto de validação:\", grid_search.best_score_)\n",
    "\n",
    "# Avaliar o modelo no conjunto de teste\n",
    "y_pred = grid_search.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(\"R^2 no conjunto de teste:\", r2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Validação:***\n",
    "A regressão Ridge tem um R2 de validação menor (0.2551) comparado ao LASSO (0.2572). Isso indica que, durante a validação, o modelo LASSO apresentou um melhor desempenho.\n",
    "\n",
    "***Teste:***\n",
    "No conjunto de teste, a regressão Ridge apresenta um R2 ligeiramente menor (0.2672) do que o LASSO (0.2679). Portanto, o modelo LASSO se sai melhor no conjunto de teste também."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor R^2 no conjunto de validação: 0.1314\n",
      "R^2 no conjunto de teste: 0.1333\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(X, y):\n",
    "    # Converter colunas booleanas para numérico\n",
    "    X['posse_de_veiculo'] = X['posse_de_veiculo'].astype(int)\n",
    "    X['posse_de_imovel'] = X['posse_de_imovel'].astype(int)\n",
    "    \n",
    "    # Excluir colunas desnecessárias se existirem\n",
    "    cols_to_drop = ['Unnamed: 0', 'id_cliente']\n",
    "    X = X.drop(columns=[col for col in cols_to_drop if col in X.columns], errors='ignore')\n",
    "    \n",
    "    # Converter colunas de X para numérico, forçando erros para NaN\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Remover colunas que só têm valores NaN\n",
    "    X = X.dropna(axis=1, how='all')\n",
    "    \n",
    "    # Garantir que y é numérico\n",
    "    y = pd.to_numeric(y, errors='coerce')\n",
    "    \n",
    "    # Remover linhas onde a resposta ou os predictores são NaN\n",
    "    valid_rows = X.notna().all(axis=1) & y.notna()\n",
    "    X = X[valid_rows]\n",
    "    y = y[valid_rows]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def stepwise_selection(X, y, initial_features=[], threshold_in=0.01, threshold_out=0.05):\n",
    "    # Pré-processar os dados\n",
    "    X, y = preprocess_data(X, y)\n",
    "    \n",
    "    included = list(initial_features)\n",
    "    while True:\n",
    "        changed = False\n",
    "        \n",
    "        # Forward step\n",
    "        excluded = list(set(X.columns) - set(included))\n",
    "        new_pvals = pd.Series(index=excluded)\n",
    "        for new_col in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(X[included + [new_col]])).fit()\n",
    "            new_pvals[new_col] = model.pvalues[new_col]\n",
    "        best_pval = new_pvals.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pvals.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed = True\n",
    "        \n",
    "        # Backward step\n",
    "        model = sm.OLS(y, sm.add_constant(X[included])).fit()\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max()\n",
    "        if worst_pval > threshold_out:\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            changed = True\n",
    "        \n",
    "        if not changed:\n",
    "            break\n",
    "    \n",
    "    return included\n",
    "\n",
    "# Suponha que seu DataFrame é chamado df e tem uma coluna 'renda' como variável resposta\n",
    "# Selecione as colunas que serão usadas como variáveis explicativas\n",
    "X = df.drop(columns=['renda'])\n",
    "y = df['renda']\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Usar preprocess_data para limpar os dados de treino e teste\n",
    "X_train, y_train = preprocess_data(X_train_raw, y_train_raw)\n",
    "X_test, y_test = preprocess_data(X_test_raw, y_test_raw)\n",
    "\n",
    "# Criar o pipeline com o modelo LASSO e o pré-processador\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', StandardScaler()),  # Normalizar os dados\n",
    "    ('lasso', Lasso())\n",
    "])\n",
    "\n",
    "# Definir os parâmetros para a busca em grid\n",
    "param_grid = {\n",
    "    'lasso__alpha': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Configurar a busca em grid\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train[selected_features], y_train)\n",
    "\n",
    "# Exibir os melhores parâmetros e o melhor score\n",
    "print(f\"Melhor R^2 no conjunto de validação: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Avaliar o modelo no conjunto de teste\n",
    "y_pred = grid_search.predict(X_test[selected_features])\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(f\"R^2 no conjunto de teste: {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Desempenho em R² no Conjunto de Validação:***\n",
    "Ridge e LASSO têm valores de R² no conjunto de validação significativamente melhores do que o Stepwise.\n",
    "O Ridge alcança um R² de 0.2551 e o LASSO um R² de 0.2572, enquanto o Stepwise fica com 0.1314. Isso sugere que os modelos Ridge e LASSO estão conseguindo explicar melhor a variabilidade dos dados no conjunto de validação.\n",
    "\n",
    "***Desempenho em R² no Conjunto de Teste:***\n",
    "Novamente, o Ridge e o LASSO apresentam melhor desempenho no conjunto de teste comparado ao Stepwise.\n",
    "O Ridge tem um R² de 0.2672, o LASSO tem 0.2679, enquanto o Stepwise fica com 0.1333. Isso indica que o Ridge e o LASSO estão proporcionando melhores previsões em dados não vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***O modelo LASSO parece ser o melhor de todos, dado que apresenta o melhor desempenho em ambos os conjuntos de dados. Ele consegue capturar a variabilidade dos dados de validação e teste de maneira mais eficaz do que o Ridge e o Stepwise.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 no conjunto de teste (Pipeline): 0.1158\n"
     ]
    }
   ],
   "source": [
    "# Criar um pipeline com transformação polinomial, escala e modelo Random Forest\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Treinar o pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar o modelo no conjunto de teste\n",
    "y_pred = pipeline.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(f\"R^2 no conjunto de teste (Pipeline): {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O teste com transformação polinomial, escala e modelo Random Forest se mostrou insatisfatório ao render um R^2 baixo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 no conjunto de teste: 0.2672790656792706\n"
     ]
    }
   ],
   "source": [
    "# Definir os parâmetros para GridSearch com uma gama mais ampla de alphas\n",
    "param_grid = {\n",
    "    'ridge__alpha': [0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Avaliar o modelo no conjunto de teste\n",
    "y_pred_test = grid_search.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "print(\"R^2 no conjunto de teste:\", r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Aumentar a gama de valores de alpha ajudou a explorar uma maior variedade de regularizações, o que melhorou o desempenho ao encontrar o melhor parâmetro para o modelo Ridge***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 no conjunto de teste com árvore de decisão: 0.0464\n"
     ]
    }
   ],
   "source": [
    "# Criar o pipeline com pré-processamento e modelo de árvore de decisão\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('tree', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Ajustar o modelo aos dados de treino\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar o modelo no conjunto de teste\n",
    "y_pred = pipeline.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(f\"R^2 no conjunto de teste com árvore de decisão: {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***O R^2 foi o menor de todos os modelos o que demonstra que o modelo de árvore de decisão não teve um bom desempenho***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor R^2 no conjunto de validação: 0.29775147309310707\n",
      "R^2 no conjunto de teste com árvore de decisão otimizada: 0.2674\n"
     ]
    }
   ],
   "source": [
    "# Definir os parâmetros para GridSearch\n",
    "param_grid = {\n",
    "    'tree__max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'tree__min_samples_split': [2, 5, 10],\n",
    "    'tree__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Criar o pipeline com pré-processamento e modelo de árvore de decisão\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('tree', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Configurar o GridSearchCV para encontrar os melhores parâmetros\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Dividir os dados em conjunto de treino e teste (75% treino, 25% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Ajustar o modelo aos dados de treino\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Exibir os melhores parâmetros e o melhor score\n",
    "print(\"Melhor R^2 no conjunto de validação:\", grid_search.best_score_)\n",
    "\n",
    "# Avaliar o modelo no conjunto de teste\n",
    "y_pred = grid_search.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(f\"R^2 no conjunto de teste com árvore de decisão otimizada: {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***A árvore de decisão otimizada conseguiu um R² de 0.2674 no conjunto de teste, o que é uma melhora em relação aos modelos anteriores. Isso indica que a árvore de decisão, com os parâmetros otimizados, conseguiu ficar em segundo lugar como modelo mais eficiente, perdendo apenas para o modelo LASSO.***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
