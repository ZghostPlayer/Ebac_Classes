{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d49e2027-e6c0-45f7-9809-cd20da9179b5",
   "metadata": {},
   "source": [
    "### Diferenças entre Random Forest e AdaBoost\n",
    "\n",
    "1. **Estratégia de Treinamento:**\n",
    "   - **Random Forest:** Treina várias árvores de decisão independentemente umas das outras e combina seus resultados usando um processo de votação (para classificação) ou média (para regressão).\n",
    "   - **AdaBoost:** Treina modelos sequencialmente, onde cada modelo foca em corrigir os erros do modelo anterior.\n",
    "\n",
    "2. **Peso dos Modelos:**\n",
    "   - **Random Forest:** Todas as árvores têm peso igual no momento da combinação dos resultados.\n",
    "   - **AdaBoost:** Dá pesos diferentes para cada modelo, dependendo de seu desempenho no conjunto de treinamento.\n",
    "\n",
    "3. **Robustez a Dados Ruídosos:**\n",
    "   - **Random Forest:** É mais robusto a dados ruidosos e outliers devido à natureza independente das árvores e uso de amostras bootstrap.\n",
    "   - **AdaBoost:** Pode ser mais sensível a outliers, já que dá mais peso a instâncias mal classificadas, incluindo possíveis outliers.\n",
    "\n",
    "4. **Complexidade:**\n",
    "   - **Random Forest:** É mais simples de implementar e ajustar, já que cada árvore é treinada de forma independente.\n",
    "   - **AdaBoost:** Pode ser mais complexo devido ao treinamento iterativo e ajuste dos pesos das instâncias.\n",
    "\n",
    "5. **Capacidade de Evitar Overfitting:**\n",
    "   - **Random Forest:** Geralmente menos propenso a overfitting devido à agregação de resultados de múltiplas árvores e amostragem aleatória.\n",
    "   - **AdaBoost:** Pode ser mais propenso a overfitting, especialmente em datasets pequenos e ruidosos.\n",
    "\n",
    "---\n",
    "**Conclusão:**\n",
    "Random Forest e AdaBoost são ambos métodos de ensemble learning, mas possuem abordagens bem distintas. Random Forest prioriza a independência das árvores, enquanto o AdaBoost foca no aprendizado sequencial. A escolha entre eles depende do tipo de problema, dados disponíveis e requisitos de desempenho.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac96685b-c914-4ddc-9bb7-7c3b472bb0f7",
   "metadata": {},
   "source": [
    "### Exemplo do AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd85f02e-2179-43a7-ba69-7766d5c978cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Carregar o dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Definir o modelo AdaBoost com o algoritmo SAMME\n",
    "clf = AdaBoostClassifier(n_estimators=100, algorithm=\"SAMME\")\n",
    "\n",
    "# Realizar a validação cruzada\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Exibir a média das pontuações\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e822c9-783d-415f-be93-906c465d7c34",
   "metadata": {},
   "source": [
    "### Hiperparâmetros importantes no AdaBoost\n",
    "\n",
    "1. **`n_estimators`**:\n",
    "   - Define o número de estimadores fracos (como árvores de decisão) a serem treinados. Um valor maior pode aumentar a performance, mas também o tempo de treinamento.\n",
    "\n",
    "2. **`learning_rate`**:\n",
    "   - Controla o peso de cada estimador fraco na combinação final. Valores menores podem exigir mais estimadores para alcançar uma boa performance.\n",
    "\n",
    "3. **`base_estimator`**:\n",
    "   - Especifica o modelo base usado como estimador fraco. Por padrão, é uma árvore de decisão `DecisionTreeClassifier`.\n",
    "\n",
    "4. **`algorithm`**:\n",
    "   - Escolhe entre os algoritmos `SAMME` e `SAMME.R`. `SAMME.R` utiliza probabilidades para atualizar os pesos e geralmente é mais rápido.\n",
    "\n",
    "5. **`random_state`**:\n",
    "   - Controla a aleatoriedade do treinamento para garantir reprodutibilidade dos resultados.\n",
    "\n",
    "---\n",
    "**Conclusão:**\n",
    "Esses hiperparâmetros são cruciais para ajustar o desempenho do AdaBoost e podem ser otimizados usando técnicas como `GridSearchCV` ou `RandomizedSearchCV`. A escolha dos valores depende do dataset e do problema específico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d3730-0c59-452f-bbe0-f8cea8e07f1d",
   "metadata": {},
   "source": [
    "### Encontrar os melhores hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1c0fcd7-167f-44d4-b341-1552e1eb7fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'algorithm': 'SAMME', 'estimator__max_depth': 3, 'learning_rate': 0.1, 'n_estimators': 150}\n",
      "Melhor pontuação: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Carregar o dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Definir o modelo base\n",
    "estimator = DecisionTreeClassifier()\n",
    "\n",
    "# Configurar os hiperparâmetros a serem testados\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'estimator__max_depth': [1, 2, 3],\n",
    "    'algorithm': ['SAMME']  # Força o uso do algoritmo SAMME\n",
    "}\n",
    "\n",
    "# Configurar o AdaBoost com o estimator\n",
    "clf = AdaBoostClassifier(estimator=estimator, algorithm='SAMME')  # Define explicitamente o algoritmo\n",
    "\n",
    "# Configurar o GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Executar o GridSearch\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Exibir os melhores hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Exibir a melhor pontuação\n",
    "print(\"Melhor pontuação:\", grid_search.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
